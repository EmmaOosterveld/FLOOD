{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f922295-c5db-4666-b727-812d27070518",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fae7d2e-a139-4778-8b9b-7db6fbf67da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c64d2-3d6a-4da0-8a52-5154ba66f9a0",
   "metadata": {},
   "source": [
    "The input in the model consists of the DEM and the first measurement of the waterdepth. In that way the UNET-model knows from what direction the water is coming. The model is trained on the training data set and tested on three different test datasets. The training data is splitted in validation and training part in another notebook. \n",
    "\n",
    "In order to run this notebook, all the datasets need to be downloaded and stored in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f28ab7d-a94d-4c93-8516-ec4ecd23963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the testing data set \n",
    "\n",
    "test_dataset = 3 # can be 1, 2 or 3\n",
    "\n",
    "# Define numbers for the test and training data. These refer to the names of the data files\n",
    "# For the first two datasets, there are 97 time steps of 30 minutes, for the third dataset there are 241 time steps of 30 minutes\n",
    "\n",
    "\n",
    "\n",
    "if test_dataset == 1:\n",
    "    numbers_test = np.linspace(500, 519, 20, dtype=int)\n",
    "    time = 97\n",
    "    \n",
    "if test_dataset == 2:\n",
    "    numbers_test = np.linspace(10000, 10020, 21, dtype=int)\n",
    "    time = 97\n",
    "\n",
    "#we use only the first 98 time steps of dataset 3\n",
    "if test_dataset == 3:\n",
    "    numbers_test = np.linspace(15001, 15010, 10, dtype=int)\n",
    "    time = 98\n",
    "    \n",
    "# The training data is the same for all datasets\n",
    "numbers_train = np.linspace(1, 80, 80, dtype=int) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5a41bd-27d0-4d8d-a247-2c4f96c8bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define path to stored DEMs and waterdepths\n",
    "\n",
    "base_path_DEM = 'C:/Users/emma1/Dropbox/Env Eng 23-24/DSAIE/Project/raw_datasets/raw_datasets/DEM'\n",
    "base_path_WD = 'C:/Users/emma1/Dropbox/Env Eng 23-24/DSAIE/Project/raw_datasets/raw_datasets/WD'\n",
    "\n",
    "output_folder = 'C:/Users/emma1/Dropbox/Env Eng 23-24/DSAIE/Project/raw_datasets/raw_datasets/Data_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc286536-fe9b-4d87-9145-13235a6fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the DEMs and waterdepth data\n",
    "test_DEM = []\n",
    "test_WD = []\n",
    "train_DEM = []\n",
    "train_WD = []\n",
    "\n",
    "for i in numbers_train:\n",
    "    file_path_DEM_train = os.path.join(base_path_DEM, f\"DEM_{i}.txt\")\n",
    "    DEM = np.loadtxt(file_path_DEM_train)\n",
    "    train_DEM.append(DEM)\n",
    "    \n",
    "    file_path_WD_train = os.path.join(base_path_WD, f\"WD_{i}.txt\") \n",
    "    WD = np.loadtxt(file_path_WD_train)\n",
    "    train_WD.append(WD)\n",
    "    \n",
    "for i in numbers_test:\n",
    "    file_path_DEM_test = os.path.join(base_path_DEM, f\"DEM_{i}.txt\")\n",
    "    DEM = np.loadtxt(file_path_DEM_test)    \n",
    "    test_DEM.append(DEM)\n",
    "     \n",
    "    file_path_WD_test = os.path.join(base_path_WD, f\"WD_{i}.txt\") \n",
    "    WD = np.loadtxt(file_path_WD_test)\n",
    "    test_WD.append(WD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7748fe-9705-4241-a8a4-c48d1a3d59af",
   "metadata": {},
   "source": [
    "## Creating and reshaping training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6100a-87a2-410a-a6e6-29d02f43e6cb",
   "metadata": {},
   "source": [
    "With the function below, the input to the model is created. The input contains a tensor with the DEM and corresponing first water level for every time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21d5aec-1154-4679-a81b-e2751f185d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_processing(DEM, WD, time):\n",
    "    \n",
    "    \"Processing of DEM and WD to correct format as input\"\n",
    "    \n",
    "    inputs = []\n",
    "    \n",
    "    for i in range(len(DEM)):\n",
    "\n",
    "        input_val = []\n",
    "        # Reshaping the DEM array to a 2D array\n",
    "        x = np.unique([row[0] for row in DEM[i]])\n",
    "        y = np.unique([row[1] for row in DEM[i]])\n",
    "        z = np.array([row[2] for row in DEM[i]]).reshape(len(y), len(x))\n",
    "    \n",
    "        # Selecting the first time step with a non-zero water depth measurement as input\n",
    "        WD_array = []\n",
    "        \n",
    "        for line in range(0, time):\n",
    "            time_step = WD[i][line]\n",
    "            \n",
    "            if any(value != 0 for value in time_step):      # The timesteps with non-zero values are selected (start of the flooding event)\n",
    "                WD_array.append(time_step.reshape(len(y), len(x)))\n",
    "            \n",
    "        # The first timestep with flooding is selected, this is an input in the model so it knows where the water is coming from        \n",
    "        first_WD = WD_array[0] \n",
    "    \n",
    "    \n",
    "        # The DEMs and corresponding first waterdepths are combined in one tensor per location and stored in train_input\n",
    "        input_val.append(z)\n",
    "        input_val.append(first_WD)\n",
    "        \n",
    "        inputs.append(torch.tensor(input_val, dtype=torch.float32))\n",
    "    return inputs\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df2d992-0026-4e76-8ae8-9e11a85dcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emma1\\AppData\\Local\\Temp\\ipykernel_14784\\2205807111.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  inputs.append(torch.tensor(input_val, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "train_input = input_processing(train_DEM, train_WD, 97)\n",
    "test_input = input_processing(test_DEM, test_WD, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194d4d4-7bea-4239-88ec-bd47c16cef6c",
   "metadata": {},
   "source": [
    "An example of the input is shown below, where a tensor is shown with the DEM corresponding first water level measured. In dataset 1, every flooding event starts in the top left corner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04889d8-9d2e-46a5-b19f-d445a3784521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000, -0.4338, -0.9741,  ...,  1.3949,  1.1974,  0.8884],\n",
      "         [ 0.3768, -0.0538, -0.5870,  ...,  1.3094,  0.9917,  0.5849],\n",
      "         [ 0.7063,  0.2907, -0.2208,  ...,  1.1202,  0.6850,  0.1888],\n",
      "         ...,\n",
      "         [-0.1749, -0.3337, -0.6197,  ...,  1.1239,  1.0451,  0.7989],\n",
      "         [-0.1829, -0.2944, -0.5222,  ...,  0.6289,  0.6465,  0.5163],\n",
      "         [-0.1654, -0.2384, -0.4206,  ...,  0.2556,  0.3745,  0.3580]],\n",
      "\n",
      "        [[ 0.0100,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b809b1-76b0-43e4-b4fd-457895ee0148",
   "metadata": {},
   "source": [
    "Below the targets for the training and testing data are computed. These consits of measured water depths at different time steps. The training dataset consists of 97 timesteps of 30 minutes. Where the first timestep is used as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc27851c-50c7-48b7-8aea-00785306a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(DEM, WD, time):\n",
    "    \n",
    "    \"Create targets of the waterdepth (WD) in correct format\"\n",
    "    \n",
    "    targets = []\n",
    "    for i in range(len(WD)):\n",
    "        array = []\n",
    "       \n",
    "        x = np.unique([row[0] for row in DEM[i]])\n",
    "        y = np.unique([row[1] for row in DEM[i]])\n",
    "        \n",
    "        # The water depths at all the timesteps are reshaped and stored in an array\n",
    "        for row in range(1, time):\n",
    "            time_step = WD[i][row]\n",
    "            array.append(time_step.reshape(len(y), len(x)))\n",
    "    \n",
    "        # A tensor is created (consisting of waterdepths at X different timesteps) and appended to the list of target tensors (targets)\n",
    "        targets.append(torch.tensor(array, dtype=torch.float32))\n",
    "    return targets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa882d5-d72d-4da0-8ebf-8f22eb8851c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "train_targets = create_targets(train_DEM, train_WD, 97)\n",
    "test_targets = create_targets(test_DEM, test_WD, time)\n",
    "\n",
    "print(len(train_targets[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37129f9b-7d1f-484d-8a4a-4c538984ead8",
   "metadata": {},
   "source": [
    "The training input and targets are combined in one training dataset: train. The same is done for the testing dataset: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5bd723-62f0-4ce0-8e3b-933ccd32b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "for dem, wd in zip(train_input, train_targets):\n",
    "    train.append((dem, wd))\n",
    "\n",
    "test = []\n",
    "\n",
    "for dem, wd in zip(test_input,  test_targets):\n",
    "    test.append((dem, wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09319b05-7ba3-4e75-b3e5-6ef0f1fa7e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "print(len(test[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa254cf1-e8f4-47d6-841a-d35613068792",
   "metadata": {},
   "source": [
    "The training and testing datasets can be stored with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c610612-8d23-4ab1-bdec-9350a096f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name =  'test_dataset_3_CNN_time_two_inputs.pt' \n",
    "\n",
    "output_file_path_test = os.path.join(output_folder, test_name)\n",
    "torch.save(test, output_file_path_test)\n",
    "\n",
    "\n",
    "#train_name = #'train_dataset_CNN_time_two_inputs.pt'\n",
    "\n",
    "#output_file_path_train = os.path.join(output_folder, train_name)\n",
    "#torch.save(train, output_file_path_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d90fa1-8ced-43e0-afb3-4672d93c474b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
