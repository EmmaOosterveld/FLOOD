{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLFOHVvq-kW8"
   },
   "source": [
    "# Project DSAIE: FLOOD1 CNN-Model with Data Augmentation\n",
    "The main task of the neural network is to predict water depth in meters based on an unseen Digital Elevation Map (DEM).\n",
    "\n",
    "The U-Net network is selected to model the water depth as it can work well with gridded data. The U-Net is based on a fully convolutional neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvYF5Vgm-kXG"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/b5/56/38e892200f8638032b64f6fc8660049f0d00ccba086cf1dcb884bd6370d2/torchvision-0.17.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.17.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.0 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from torch==2.2.0->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.0->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lydia\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.0->torchvision) (1.3.0)\n",
      "Using cached torchvision-0.17.0-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KxiBxwYW-kXI"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_ctx' from 'torch.library' (C:\\Users\\lydia\\anaconda3\\Lib\\site-packages\\torch\\library.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\_meta_registrations.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_ops\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_custom_ops.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_op\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     _custom_op_with_schema,\n\u001b[0;32m      5\u001b[0m     _find_custom_op,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     validate_namespace,\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ctx\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_op\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimpl_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_op\u001b[39m(qualname, func_or_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_ctx' from 'torch.library' (C:\\Users\\lydia\\anaconda3\\Lib\\site-packages\\torch\\library.py)"
     ]
    }
   ],
   "source": [
    "## Useful libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import time\n",
    "\n",
    "from cycler import cycler\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the color scheme\n",
    "sns.set_theme()\n",
    "colors = ['#0076C2', '#EC6842', '#A50034', '#009B77', '#FFB81C', '#E03C31', '#6CC24A', '#EF60A3', '#0C2340', '#00B8C8', '#6F1D77']\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cs6zMoRB-0pD",
    "outputId": "d85febc8-9c8d-4844-c2e5-c1cc32cb06a0"
   },
   "outputs": [],
   "source": [
    "#Change this cell to have the local path to the correct folders\n",
    "\n",
    "# go to FLOOD/CNN_model\n",
    "%cd ..\n",
    "# go to FLOOD/_model/model\n",
    "folder_path = 'Models'\n",
    "%cd \"$folder_path\"\n",
    "import CNN_UNet as unet\n",
    "\n",
    "# go to FLOOD/CNN_model\n",
    "%cd ..\n",
    "# go to FLOOD/CNN_model/Data/Preprocessed_data\n",
    "folder_path = 'Data/Preprocessed_data'\n",
    "%cd \"$folder_path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVPkbHIZ-kXM"
   },
   "source": [
    "## Training dataset and selection of test dataset\n",
    "\n",
    "As a first step the datasets are loaded. The data is pre-processed before, so it can be downloaded directly.\n",
    "In the cell below one test dataset should be selected for testing the performance of the model.\n",
    "- test dataset 1: 20 DEM and WD with grid size of 64x64 km, time scale 4 days and starting point flood not changing\n",
    "- test dataset 2: 20 DEM and WD with grid size of 64x64 km, time scale 4 days and starting point flood changing\n",
    "- test dataset 3: 20 DEM and WD with grid size of 128x128 km, time scale 10 days and starting point flood changing\n",
    "\n",
    "The training data consists of 80 DEM locations and corresponding waterdepth (WD).\n",
    "\n",
    "It is important to mention that in order to be able to test dataset 3, the dataset is cut off to the first 4 days (instead of 10 days).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCIVBmVy-kXO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.load('train_dataset_CNN_time_two_inputs.pt')\n",
    "\n",
    "#select the test dataset\n",
    "dataset = 1\n",
    "\n",
    "test_dataset = torch.load('test_dataset_1_CNN_time_two_inputs.pt')\n",
    "#test_dataset = torch.load('test_dataset_2_CNN_time_two_inputs.pt')\n",
    "#test_dataset = torch.load('test_dataset_3_CNN_time_two_inputs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8CzMpMR-kXQ"
   },
   "source": [
    "### Plot the inputs and outputs for one example.\n",
    "\n",
    "The inputs and outputs are as follows:\n",
    "\n",
    "Inputs:\n",
    "- digital elevation model (DEM)\n",
    "- Water depth (WD) for the first time step\n",
    "\n",
    "Output:\n",
    "- Water depth for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "xgQ9fQaD-kXR",
    "outputId": "e3011d01-d840-4dec-c379-be3f69220489"
   },
   "outputs": [],
   "source": [
    "inputs, outputs = train_dataset[0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 7))\n",
    "\n",
    "axs[0].imshow(inputs[0].cpu(), cmap='terrain', origin='lower')\n",
    "axs[0].set_title('DEM')\n",
    "\n",
    "axs[1].imshow(inputs[1].cpu(), cmap='Blues', origin='lower')\n",
    "axs[1].set_title('Water depth [m] first time step')\n",
    "\n",
    "axs[2].imshow(outputs[-1].cpu(), cmap='Blues', origin='lower')\n",
    "axs[2].set_title('Water depth [m]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP6BQSRRglNQ"
   },
   "source": [
    "###Data Augmentation###\n",
    "\n",
    "This code introduces random rotations to augment a training dataset. It selects rotation angles randomly from a predefined list [90, 180, 270], applies these rotations to input and output tensors, and ensures the rotated tensors maintain original dimensions. Augmented data is appended to the original training dataset, enhancing its diversity for improved model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5Is3HZhgljk",
    "outputId": "c120602b-ddd8-4234-b716-511136c63c6c"
   },
   "outputs": [],
   "source": [
    "# Define a list of rotation angles\n",
    "rotation_angles = [90, 180, 270]\n",
    "\n",
    "# Create a list to store augmented data\n",
    "augmented_data_list = []\n",
    "\n",
    "# Assuming train_dataset is your entire training dataset\n",
    "for i in range(len(train_dataset)):\n",
    "    inputs, outputs = train_dataset[i]\n",
    "\n",
    "    # Randomly choose a rotation angle from the predefined list\n",
    "    rotation_angle = torch.randint(len(rotation_angles), (1,)).item()\n",
    "    selected_angle = rotation_angles[rotation_angle]\n",
    "\n",
    "    # Apply rotation to input data\n",
    "    rotated_input = F.rotate(inputs, selected_angle)\n",
    "\n",
    "    # Apply rotation to output data\n",
    "    rotated_output = F.rotate(outputs, selected_angle)\n",
    "\n",
    "    # Ensure the rotated tensors have the same size as the original tensors\n",
    "    rotated_input = F.resize(rotated_input, inputs.shape[-2:])\n",
    "    rotated_output = F.resize(rotated_output, outputs.shape[-2:])\n",
    "\n",
    "    # Append augmented data to the list\n",
    "    augmented_data_list.append((rotated_input, rotated_output))\n",
    "\n",
    "# Combine original dataset with augmented data\n",
    "train_dataset2_augmented = train_dataset + augmented_data_list\n",
    "print(len(train_dataset))\n",
    "train_dataset = train_dataset2_augmented\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGVqzbeSnrEk"
   },
   "source": [
    "This code snippet generates a visualization of both original and augmented samples from the training dataset. It assumes that `train_dataset` is the dataset containing both original and augmented samples. The visualization is designed to display up to 10 samples, comparing the original Digital Elevation Model (DEM) and Water Depth map (WD) with their augmented counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LurM6i6inqA-",
    "outputId": "4cde6a16-7762-4724-f178-f50d919208cd"
   },
   "outputs": [],
   "source": [
    "# Assuming train_dataset is your dataset\n",
    "num_samples = min(10, len(train_dataset))  # Display up to 10 samples\n",
    "\n",
    "# Visualize a subset of original and augmented inputs and outputs in the train_dataset\n",
    "fig, axes = plt.subplots(num_samples, 4, figsize=(20, 5 * num_samples))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Original input and output\n",
    "    original_inputs, original_outputs = train_dataset[i]\n",
    "\n",
    "    # Plot the original input\n",
    "    axes[i, 0].imshow(original_inputs[0].cpu(), cmap='terrain', origin='lower')\n",
    "    axes[i, 0].set_title(f'Original DEM - Sample {i}')\n",
    "\n",
    "    # Plot the original output\n",
    "    axes[i, 1].imshow(original_outputs[-1].cpu(), cmap='Blues', origin='lower')\n",
    "    axes[i, 1].set_title(f'Original WD - Sample {i}')\n",
    "\n",
    "    # Augmented input and output\n",
    "    augmented_inputs, augmented_outputs = train_dataset[len(train_dataset) // 2 + i]  # assuming len(train_dataset) is even\n",
    "\n",
    "    # Plot the augmented input\n",
    "    axes[i, 2].imshow(augmented_inputs[0].cpu(), cmap='terrain', origin='lower')\n",
    "    axes[i, 2].set_title(f'Augmented DEM - Sample {i}')\n",
    "\n",
    "    # Plot the augmented output\n",
    "    axes[i, 3].imshow(augmented_outputs[-1].cpu(), cmap='Blues', origin='lower')\n",
    "    axes[i, 3].set_title(f'Augmented WD - Sample {i}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOcjDktm-kXY"
   },
   "source": [
    "### Normalization\n",
    "\n",
    "Since the input and output values may have very different ranges, it is important to perform normalization to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0r1jL7bt-kXZ"
   },
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, scaler_x, scaler_y):\n",
    "    min_x, max_x = scaler_x.data_min_[0], scaler_x.data_max_[0]\n",
    "    min_y, max_y = scaler_y.data_min_[0], scaler_y.data_max_[0]\n",
    "    normalized_dataset = []\n",
    "    for idx in range(len(dataset)):\n",
    "        x = dataset[idx][0]\n",
    "        y = dataset[idx][1]\n",
    "        norm_x = (x - min_x) / (max_x - min_x)\n",
    "        norm_y = (y - min_y) / (max_y - min_y)\n",
    "        normalized_dataset.append((norm_x, norm_y))\n",
    "    return normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3I3R1pP-kXc"
   },
   "outputs": [],
   "source": [
    "# Normalize the inputs and outputs using training dataset\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "for idx in range(len(train_dataset)):\n",
    "    scaler_x.partial_fit(train_dataset[idx][0].reshape(inputs.shape[0], -1).T.cpu())\n",
    "    scaler_y.partial_fit(train_dataset[idx][1].reshape(-1, 1).cpu())\n",
    "\n",
    "normalized_train_dataset = normalize_dataset(train_dataset, scaler_x, scaler_y)\n",
    "normalized_test_dataset = normalize_dataset(test_dataset, scaler_x, scaler_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN4OfaBt-tLh"
   },
   "source": [
    "The training data is splitted in a training and validation part. The model is trained on the training data (80%) and overfitting is prevented by using validation data (20%). Every time the code is runned, a different split between validation and training data is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wNYVtQ2-kXe"
   },
   "outputs": [],
   "source": [
    "# Split dataset into train, validation\n",
    "train_percnt = 0.8\n",
    "train_size = int(train_percnt * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(normalized_train_dataset, [train_size, val_size]) #different split for each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ilFDdC1-kXg"
   },
   "source": [
    "# Model\n",
    "\n",
    "The U-Net network is selected to model the water depth as it can work well with gridded data. The U-Net is based on a fully convolutional neural network. To speed up the running time, the model should be runned on a GPU.\n",
    "\n",
    "The network has an encoder and decoder part. In this encoder part the spatial information is reduced while the feature information is increased. The double convolution consists of twice a 2D convolution followed by batch normalization, a ReLU activation function and a max pooling operation for downsampling the spatial dimension. The batch normalization normalizes the input of each layer within a mini-batch, to address for variance explosion.\n",
    "A choice was made to use ReLU6 as an activation function. ReLU6 limits the output to a maximum size of 6. This means that any input below 0 will be removed, while any input above 6 is converted to 6. ReLU6 improves the robustness of low-precision computation. The model performed better when using ReLU6 compared to ReLU.\n",
    "After this step the data downsampled using 5 max pooling layers. In this encoder the spatial information is reduced while the feature information is increased.\n",
    "\n",
    "The decoder consists of a sequence of up-convolutions. The data upsampled 5 times and goes trough the double convlution function every time to reduce the number of channels.\n",
    "\n",
    "Input in the U-Net network:\n",
    "- Series with DEMs\n",
    "- corresponding first time waterdpeth (WD)\n",
    "\n",
    "Targets:\n",
    "- Waterdepths at 96 timesteps(97 - first time step), correspinding to 4 days if 30-minute measurements.\n",
    "\n",
    "The model is based on one step forecast, where all targets are predicted in one go. There are two input channels in the network as there are two inputs and 96 classes as there are 96 timesteps to predict per DEM (targets).\n",
    "The  number of input and output channels per layer is defined by calibrating the network to find the optimal values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmqJ-UF2-kXn"
   },
   "outputs": [],
   "source": [
    "model = unet.UNet(n_channels = 2, n_classes = 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DutAFmlA-kXp"
   },
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KXIJBcRJglr"
   },
   "source": [
    "The model is trained with the 'train_epoch' function below. The losses are computed with the mean squared error (MSE) with the prediction data and targets. The loss is minimized by optimizing the weights in the network. The evaluation function is used to compute the losses for the validation data. The losses are computed the same way as in training. However, the weights are not optimized in validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_KfeSzK-kXp"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train() # specifies that the model is in training mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "\n",
    "        # Model prediction\n",
    "        preds = model(x)\n",
    "\n",
    "        # MSE loss function\n",
    "        loss = nn.MSELoss()(preds, y)\n",
    "\n",
    "        losses.append(loss.cpu().detach())\n",
    "\n",
    "        # Backpropagate and update weights\n",
    "        loss.backward()   # compute the gradients using backpropagation\n",
    "        optimizer.step()  # update the weights with the optimizer\n",
    "        optimizer.zero_grad(set_to_none=True)   # reset the computed gradients\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJUNthfk-kXq"
   },
   "outputs": [],
   "source": [
    "def evaluation(model, loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval() # specifies that the model is in evaluation mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[0]\n",
    "            y = batch[1]\n",
    "\n",
    "            # Model prediction\n",
    "            preds = model(x)\n",
    "\n",
    "            # MSE loss function\n",
    "            loss = nn.MSELoss()(preds, y)\n",
    "            losses.append(loss.cpu().detach())\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJz_O08Z-kXs"
   },
   "source": [
    "### Define the training paramters, the optimizer, and the dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Va10ozzKslB"
   },
   "source": [
    "The three hyperparameters (learning rate, batch size and number of epochs) are calibrated by hand. The values below resulted in the best performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLX-pLAj-kXt"
   },
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.001 #proven to be best value\n",
    "batch_size = 8\n",
    "num_epochs = 300\n",
    "\n",
    "# Create the optimizer to train the neural network via back-propagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training and validation dataloaders to \"feed\" data to the model in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(normalized_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UbDz_Jc-kXv"
   },
   "source": [
    "## Training and validating\n",
    "\n",
    "The next step is to train the U-Net model for a number of epochs.\n",
    "During training the model with the training and validation data, both the training and test losses are recorded. To compare the models based on runtimes the 'start_time' and 'end_time' variables are added, which calculates the run time of the training part.\n",
    "For each epoch the 'train_epoch' function is used, which returns the train_loss. The evaluation function calculates the validation loss for each epoch.\n",
    "If for an epoch the validation loss is lower than the 'best_loss' so far, the 'best_loss' is updated. In the 'best_epoch' the best epoch number is saved.\n",
    "If the best_loss does not change for more then 25 epoch the model is stopped (early stopping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3dirPE3-kXw",
    "outputId": "23ce1a40-fbd5-4b40-ba88-5e1b4b7011d7"
   },
   "outputs": [],
   "source": [
    "# Lists to store losses and accuracies\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Keep track of the best validation accuracy and save the best model\n",
    "best_loss = np.inf #set to infinity to make sure the loss of the first epoch is saved\n",
    "best_model_path = 'best_model_data_aug.pth'\n",
    "\n",
    "# Parameter to calculate the runtime of the model\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer)\n",
    "    training_losses.append(train_loss)\n",
    "    validation_loss = evaluation(model, val_loader)\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    if best_loss > validation_loss:\n",
    "        print(f'Lowest loss updated at epoch {epoch}: {validation_loss:.5f}')\n",
    "        best_loss = validation_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    if epoch - best_epoch > 25: #stop if the validation loss has not improved for more than 25 epochs\n",
    "        break\n",
    "\n",
    "  # print all losses every fifth epoch\n",
    "    if epoch%5 == 0:\n",
    "        print(\"epoch:\",epoch, \"\\t training loss:\", np.round(train_loss,5), # we print loss and not accuracy\n",
    "                              \"\\t validation loss:\", np.round(validation_loss,5),\n",
    "                              \"\\t best loss:\", np.round(best_loss, 5))\n",
    "\n",
    "# Check the run time of the model\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVFnbaixwXmt",
    "outputId": "74c105a9-7cce-4705-aa92-1949c5682ff8"
   },
   "outputs": [],
   "source": [
    "# Load the best model after training is complete\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ivy5Kjo0-kXy",
    "outputId": "f06c05a5-5dca-43c3-ccc5-517f378adec7"
   },
   "outputs": [],
   "source": [
    "# print the test loss for the selected test dataset\n",
    "model.to('cpu')\n",
    "test_loss = evaluation(model, test_loader)\n",
    "print(f'mean test_loss: {test_loss}')\n",
    "\n",
    "#general performance of the model\n",
    "print(f'runtime in seconds: {run_time:.2f}')\n",
    "print(f'validation loss last epoch: {validation_losses[-1]:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8tajpAy-kXz"
   },
   "source": [
    "# Visualize results\n",
    "\n",
    "In this part the performance of the trained model are visualized. First the training and validation losses are shown in a figure. From this it can become clear if both losses are descreasing over the epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jl2-W3--kX0"
   },
   "source": [
    "## Losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "i-9pONHz-kX1",
    "outputId": "0433e69b-8ca0-484d-c7f2-caff4fecfef7"
   },
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label='Training')\n",
    "plt.plot(validation_losses, label='Validation')\n",
    "plt.yscale('log')\n",
    "plt.title('CNN Losses without data augmentation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy3e723V-kX2"
   },
   "source": [
    "## Visualize the test dataset predictions\n",
    "\n",
    "To have a visual idea of the quality of the predictions for the test dataset a random id of the test dataset is selected and visualized for three timesteps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908
    },
    "id": "kAGeZe6C-kX8",
    "outputId": "67a0a22b-87aa-4840-fa63-cc748f193a66"
   },
   "outputs": [],
   "source": [
    "time_step = [1, 37, 95] #Just for visualization three time_steps are selected to have an idea of the developed over time\n",
    "\n",
    "for i in time_step:\n",
    "    data_id = 4 #random number of one of the test dataset id\n",
    "    x = normalized_test_dataset[data_id][0].unsqueeze(0)\n",
    "    WD = normalized_test_dataset[data_id][1]\n",
    "    pred_WD = model(x).detach()\n",
    "\n",
    "    if dataset == 3: #different reshape values\n",
    "    DEM = scaler_x.inverse_transform(x[0].reshape(2,-1).T.cpu())[:,0].reshape(128,128)\n",
    "    real_WD = scaler_y.inverse_transform(WD[i].reshape(-1,1).cpu()).reshape(128,128)\n",
    "    pred_WD = scaler_y.inverse_transform(pred_WD[0][i].reshape(-1,1).cpu()).reshape(128,128)\n",
    "    else:\n",
    "    DEM = scaler_x.inverse_transform(x[0].reshape(2,-1).T.cpu())[:,0].reshape(64,64)\n",
    "    real_WD = scaler_y.inverse_transform(WD[i].reshape(-1,1).cpu()).reshape(64,64)\n",
    "    pred_WD = scaler_y.inverse_transform(pred_WD[0][i].reshape(-1,1).cpu()).reshape(64,64)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "    max_WD = max(pred_WD.max(), real_WD.max())\n",
    "    axs[0].imshow(DEM.squeeze(), cmap='terrain', origin='lower')\n",
    "    axs[1].imshow(real_WD.squeeze(), vmin = 0, vmax=max_WD, cmap='Blues', origin='lower')\n",
    "    axs[2].imshow(pred_WD.squeeze(), vmin = 0, vmax=max_WD,cmap='Blues', origin='lower')\n",
    "\n",
    "    plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = DEM.min(), vmax=DEM.max()),\n",
    "                              cmap='terrain'), fraction=0.05, shrink=0.8, ax=axs[0])\n",
    "    plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_WD),\n",
    "                              cmap='Blues'), fraction=0.05, shrink=0.8, ax=axs[1])\n",
    "    plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_WD),\n",
    "                              cmap='Blues'), fraction=0.05, shrink=0.8, ax=axs[2])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axis('off')\n",
    "        \n",
    "    axs[0].set_title('Input DEM [m]')\n",
    "    axs[1].set_title(f'Target Real WD [m] after {(i / 2) + 0.5} h')\n",
    "    axs[2].set_title(f'Predicted WD [m] after {(i / 2) + 0.5} h')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulPXYhgK-kX9"
   },
   "source": [
    "To include all datasets in the testset the figure below shows the loss for each testing set. From this the range of test losses is visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e8f_EvZ-kX-"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "\n",
    "        # Model prediction\n",
    "        preds = model(x)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "# concatenate all predictions\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "\n",
    "# select all outputs from test dataset\n",
    "test_WD = torch.stack([normalized_test_dataset[i][1] for i in range(len(normalized_test_dataset))])\n",
    "\n",
    "# loss on the test dataset per sample\n",
    "test_loss = torch.stack([nn.MSELoss()(all_preds[i], test_WD[i]) for i in range(len(all_preds))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "eamGwPe3-kX_",
    "outputId": "a2f8364d-41b6-49d0-fb16-ac2af2120dc5"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_loss.cpu())\n",
    "plt.title('Test loss per sample')\n",
    "plt.xlabel('Sample id');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTA4SnxaMfun",
    "outputId": "9132e49f-ba71-4874-acfe-4fea0cbd2698"
   },
   "outputs": [],
   "source": [
    "#Values of the test loss from the graph above\n",
    "print(f'Minimum test loss: {test_loss.min():.5f} and maximum test loss: {test_loss.max():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX3VV4Y--kYC"
   },
   "source": [
    "### Visualize training data\n",
    "\n",
    "As an extra check of the quality of the model two training DEM's are shown with their corresponding target en predicted WD map. Based on this it can be visualy inspected if the model training performs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "JPWQlnPl-kYE",
    "outputId": "3f920a1e-f98e-4daf-a13e-afbdf6660f00"
   },
   "outputs": [],
   "source": [
    "time_step = 95 #Visualizing only the last time step\n",
    "\n",
    "data_id = [1, 4] #two random sample id are selected\n",
    "\n",
    "for i in data_id:\n",
    "    x = normalized_train_dataset[i][0].unsqueeze(0)\n",
    "    WD = normalized_train_dataset[i][1]\n",
    "    pred_WD = model(x).detach()\n",
    "\n",
    "    DEM = scaler_x.inverse_transform(x[0].reshape(2,-1).T.cpu())[:,0].reshape(64,64)\n",
    "    real_WD = scaler_y.inverse_transform(WD[time_step].reshape(-1,1).cpu()).reshape(64,64)\n",
    "    pred_WD = scaler_y.inverse_transform(pred_WD[0][time_step].reshape(-1,1).cpu()).reshape(64,64)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "    max_WD = max(pred_WD.max(), real_WD.max())\n",
    "\n",
    "    axs[0].imshow(DEM.squeeze(), cmap='terrain', origin='lower')\n",
    "    axs[1].imshow(real_WD.squeeze(), vmin = 0, vmax=max_WD, cmap='Blues', origin='lower')\n",
    "    axs[2].imshow(pred_WD.squeeze(), vmin = 0, vmax=max_WD,cmap='Blues', origin='lower')\n",
    "\n",
    "    plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = DEM.min(), vmax=DEM.max()),\n",
    "                              cmap='terrain'), fraction=0.05, shrink=0.9, ax=axs[0])\n",
    "    plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_WD),\n",
    "                              cmap='Blues'), fraction=0.05, shrink=0.9, ax=axs[1])\n",
    "    plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_WD),\n",
    "                              cmap='Blues'), fraction=0.05, shrink=0.9, ax=axs[2])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axis('off')\n",
    "\n",
    "    print(f'MAP show training data for data_id {i}')\n",
    "    axs[0].set_title('DEM')\n",
    "    axs[1].set_title(f'Real WD (m) after {(time_step / 2) + 0.5} h')\n",
    "    axs[2].set_title(f'Predicted WD (m) after {(time_step / 2) + 0.5} h')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPX5Jf6fIKb0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb1b16fbf94c3a099de98626de7352088f13e98c2a0ec94a62819c39fd5389e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
